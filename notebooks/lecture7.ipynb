{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture7　パターン認識1\n",
    "<div dir='rtl'>\n",
    "2022.4岩政\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最も簡単なSVMの利用\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC\n",
    "\n",
    "より"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "\n",
    "X = np.array([[ 7.0588078 , -8.35541248],\n",
    "        [ 5.37042238, -2.44715237],\n",
    "        [ 9.49649411, -3.7902975 ],\n",
    "        [10.48848359, -2.75858164],\n",
    "        [ 6.53571063, -9.03691624],\n",
    "        [ 8.07502382, -4.25949569],\n",
    "        [ 6.50071007, -9.32119564],\n",
    "        [ 8.98426675, -4.87449712],\n",
    "        [ 6.08870085, -7.92832964],\n",
    "        [ 6.77939107, -7.35347717]])\n",
    "y = np.array([1, 0, 0, 0, 1, 0, 1, 0, 1, 1])\n",
    "\n",
    "# データセットを描画する。\n",
    "fig, ax = plt.subplots(facecolor=\"w\")\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, s=20, cmap=\"Paired\")\n",
    "\n",
    "#\n",
    "clf = svm.SVC(kernel='linear', C=1000) # clf : classificationの略, 線形カーネル（内積）\n",
    "clf.fit(X, y)\n",
    "\n",
    "# 分類平面及びマージンを描画する。\n",
    "XX, YY = np.meshgrid(np.linspace(*ax.get_xlim(), 100), np.linspace(*ax.get_ylim(), 100))\n",
    "xy = np.column_stack([XX.ravel(), YY.ravel()])\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "ax.contour(\n",
    "    XX, YY, Z, colors=\"k\", levels=[-1, 0, 1], alpha=0.5, linestyles=[\"--\", \"-\", \"--\"]\n",
    ")\n",
    "\n",
    "# サポートベクタを白丸でプロット\n",
    "ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=200, c='w', edgecolors='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([[6,-9],[8, -5],[10,-3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([[10,-3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0],X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "# データセットを作成する。\n",
    "X, y = make_blobs(n_samples=10, centers=2, random_state=6)\n",
    "\n",
    "# データセットを描画する。\n",
    "fig, ax = plt.subplots(facecolor=\"w\")\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, s=20, cmap=\"Paired\")\n",
    "\n",
    "# 学習する。\n",
    "#clf = svm.LinearSVC(C=1000)\n",
    "clf = svm.SVC(kernel='linear', C=1000) # clf : classificationの略, 線形カーネル（内積）\n",
    "clf.fit(X, y)\n",
    "\n",
    "# 分類平面及びマージンを描画する。\n",
    "XX, YY = np.meshgrid(np.linspace(*ax.get_xlim(), 100), np.linspace(*ax.get_ylim(), 100))\n",
    "xy = np.column_stack([XX.ravel(), YY.ravel()])\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "ax.contour(\n",
    "    XX, YY, Z, colors=\"k\", levels=[-1, 0, 1], alpha=0.5, linestyles=[\"--\", \"-\", \"--\"]\n",
    ")\n",
    "\n",
    "# サポートベクタを白丸でプロット\n",
    "ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=200, c='w', edgecolors='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ハードマージン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_classification, make_circles, make_moons \n",
    "\n",
    "# 散布図で独自のカラーマップを使用\n",
    "from matplotlib.colors import ListedColormap \n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2クラス(0, 1)のデータ生成，詳細は次を参照  \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification( n_samples=100, n_features=2, n_informative=2, n_redundant=0, \n",
    "                            n_classes=2, n_clusters_per_class=1, \n",
    "                            class_sep=2.0, #　大きいほどクラス分離の距離が大きい \n",
    "                            shift=None, \n",
    "                            random_state=5) # 整数を与えると乱数の再現性がある\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap=cm_bright, edgecolors='k')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smv.SVC のドキュメント  \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html  \n",
    "http://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1000) # clf : classificationの略, 線形カーネル（内積）\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbar = plt.scatter(X[:, 0], X[:, 1], s=30, c=y, cmap=cm_bright) # c=y, yが示すラベル0, 1で色分け\n",
    "plt.colorbar(cbar)\n",
    "# plot the decision function\n",
    "ax = plt.gca() # get current axis\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "# 超平面までの距離を求め，次にグリッドに合わせてreshape((30,30))\n",
    "Z = clf.decision_function(xy).reshape(XX.shape) \n",
    "# マージンの境界線と超平面を等高線に描く\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5, #等高線の本数と間隔をlevelsで指定\n",
    "           linestyles=['--', '-', '--'])\n",
    "# サポートベクタを白丸でプロット\n",
    "ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=200, c='w', edgecolors='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX=np.array([[1.0, -3.0], [1.0, -2.5]])\n",
    "judge = clf.predict(testX)\n",
    "judge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Circles　円状のデータ生成　\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_circles(noise = 0.001, random_state=0)\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap=cm_bright, edgecolors='k')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='rbf', C=1000) # ガウシアンカーネル\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbar = plt.scatter(X[:, 0], X[:, 1], s=30, c=y, cmap=cm_bright) # yは，ラベル0, 1があり，それで色分け\n",
    "plt.colorbar(cbar)\n",
    "# plot the decision function\n",
    "ax = plt.gca() # get current axis\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = clf.decision_function(xy).reshape(XX.shape) #超平面までの距離を求め，次に グリッドに合わせてreshape((30,30))\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], #等高線の本数と間隔をlevelsで指定\n",
    "           alpha=0.5, linestyles=['--', '-', '--'])\n",
    "# サポートベクタを白丸でプロット\n",
    "ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=200, c='w', edgecolors='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moons 月状のデータ生成　http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(noise = 0.05, random_state=0)\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap=cm_bright, edgecolors='k')\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='poly', degree=3, coef0=1.0, C=1000) # 多項式カーネル\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbar = plt.scatter(X[:, 0], X[:, 1], s=30, c=y, cmap=cm_bright) # yは，ラベル0, 1があり，それで色分け\n",
    "plt.colorbar(cbar)\n",
    "# plot the decision function\n",
    "ax = plt.gca() # get current axis\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = clf.decision_function(xy).reshape(XX.shape) #超平面までの距離を求め，次に グリッドに合わせてreshape((30,30))\n",
    "# plot decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5, #等高線の本数と間隔をlevelsで指定\n",
    "           linestyles=['--', '-', '--'])\n",
    "# サポートベクタを白丸でプロット\n",
    "ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=200, c='w', edgecolors='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM ソフトマージン\n",
    "sklearn.model_selection.train_test_split http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html  \n",
    "sklearn.metrics http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics  \n",
    "\n",
    "matplotlibのカラーマップを使用\n",
    "https://matplotlib.org/users/colormaps.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm # maplotlibのカラーマップを使用\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import   accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification( n_samples=100, n_features=2, n_informative=2, n_redundant=0, \n",
    "                            n_classes=2, n_clusters_per_class=1, \n",
    "                            class_sep=0.4, #　大きいほどクラス分離の距離が大きい \n",
    "                            shift=None, \n",
    "                            random_state=5) # 整数を与えると乱数の再現性がある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### トレーニングデータとテストデータに分離（split）\n",
    "sklearn.model_selection.train_test_split  \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "plt.scatter(X_train[:,0], X_train[:,1], c=y_train, cmap=cm.bwr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=10000) # Cの値を大きくして，なるべく他クラスへの混入を認めない\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train[:, 0], X_train[:, 1], s=30, c=y_train, cmap=cm.bwr)\n",
    "# plot hyper-plane and margin liness as the lines\n",
    "ax = plt.gca() # get current axis\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "# create grid to evaluate the lines\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "# 超平面までの距離を求め，次にグリッドに合わせてreshape((30,30))\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "# マージンの境界線と超平面を等高線に描く\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5, #等高線の本数と間隔をlevelsで指定\n",
    "           linestyles=['--', '-', '--'])\n",
    "# plot support vectors\n",
    "#ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=200, c='w', edgecolors='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### トレーニングデータに対する評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0:10]\n",
    "print('トレーニングデータ　正解率', clf.score(X_train, y_train))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train)\n",
    "print(\"予測値: %s\" % y_train_pred)\n",
    "print(\"真値　: %s\" % y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トレーニングデータに対する評価，下記のaccuracy と上記のclf.score()は同じ計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('confusion = \\n %s' % confusion_matrix(y_train, y_train_pred)) # 混同行列\n",
    "print('accuracy = %f ' % accuracy_score(y_train, y_train_pred))  # 正答率\n",
    "print('precision = %f ' % precision_score(y_train, y_train_pred)) # 適合率\n",
    "print('recall = %f ' % recall_score(y_train, y_train_pred)) # 再現率\n",
    "print('F-measure = %f' % f1_score(y_train, y_train_pred)) # F-値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( classification_report(y_train, y_train_pred)) # 正答率（accuracy）はavg/totalに"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の結果の見方，\"0\", \"1\"はクラス名で，それぞれの立場での 評価指標が示されている。\n",
    "上記の一つ一つの評価では，\"1\"の立場で見ていることと同じである。また，F-measureとf1-scoreは同じ量を示す。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### テストデータに対する評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(X_test)\n",
    "print(\"予測値: %s\" % y_test_pred)\n",
    "print(\"真値　: %s\" % y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('テストデータ　　　　　正解率', clf.score(X_test, y_test))   \n",
    "print('confusion = \\n %s' % confusion_matrix(y_test, y_test_pred))\n",
    "print('accuracy = %f ' % accuracy_score(y_test, y_test_pred))\n",
    "print('precision = %f ' % precision_score(y_test, y_test_pred))\n",
    "print('recall = %f ' % recall_score(y_test, y_test_pred))\n",
    "print('F-measure = %f' % f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test[:, 0], X_test[:, 1], s=30, c=y_test, cmap=cm.bwr)\n",
    "ax = plt.gca() # get current axis\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,            linestyles=['--', '-', '--'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSerachの使用例\n",
    "sklearn.model_selection.GridSearchCV  \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "3.2. Tuning the hyper-parameters of an estimator\n",
    "http://scikit-learn.org/stable/modules/grid_search.html#grid-search  \n",
    "\n",
    "Mlxtend (machine learning extensions) is a Python library of useful tools for the day-to-day data science tasks <br>\n",
    "https://rasbt.github.io/mlxtend/\n",
    "- Plotting Decision Regions https://rasbt.github.io/mlxtend/user_guide/plotting/plot_decision_regions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm # maplotlibのカラーマップを使用\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions #決定領域のプロット，外部ライブラリを利用\n",
    "#上記のインストールはAnacondaとは別途必要\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Num = 400 # 全サンプル数\n",
    "CV = 5    # サンプル数をCV(Cross Validation)だけ分割する\n",
    "X, y = make_classification( n_samples=Num, n_features=2, n_informative=2, n_redundant=0, \n",
    "                            n_classes=2, n_clusters_per_class=1, \n",
    "                            class_sep=1.0, #　分離度\n",
    "                            shift=None, \n",
    "                            random_state=5) # 乱数の再現性\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap=cm.bwr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# グリッドサーチ用パラメータの設定\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[0.1, 1.0, 10.0], 'gamma':[0.01, 0.1, 1.0, 10.0]}\n",
    "svc = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グリッドサーチの実行\n",
    "clf = GridSearchCV(svc, parameters, scoring='accuracy', cv=CV)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適パラメータの表示\n",
    "print('Best accuracy = ',clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適パラメータによる識別器を全データに適用，テストデータは後述\n",
    "best_clf = clf.best_estimator_\n",
    "pred = best_clf.predict(X)\n",
    "\n",
    "print('Accuracy score = ',accuracy_score(y, pred))\n",
    "print(classification_report(y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 新テストデータの作成\n",
    "今回，度，make_classificationを用いて，データを発生させ，それをテストデータに用いる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Num = 100 # 追加サンプル数\n",
    "X_test, y_test = make_classification( n_samples=Num, n_features=2, n_informative=2, n_redundant=0, \n",
    "                            n_classes=2, n_clusters_per_class=1, \n",
    "                            class_sep=1.0, #　分離度\n",
    "                            shift=None, \n",
    "                            random_state=1) # 異なる確率過程\n",
    "plt.scatter(X_test[:,0], X_test[:,1], c=y_test, cmap=cm.bwr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_clf.predict(X_test) # y_testに対するprediction\n",
    "\n",
    "print('Accuracy score = ',accuracy_score(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12,8), sharex=True, sharey=True)\n",
    "plot_decision_regions(X,y, clf=best_clf, ax=axes[0], legend=2)\n",
    "axes[0].set_xlabel('(a) Traing data')\n",
    "\n",
    "plot_decision_regions(X_test, y_test, clf=best_clf, ax=axes[1], legend=2)\n",
    "axes[1].set_xlabel('(b) Test data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM 多クラス分類，Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import datasets\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions #決定領域のプロット，外部ライブラリを利用\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "irisデータのうち，sepal（がく）と petal（花びら）の長さ[cm]によるクラス分類を行う。  \n",
    "iris.dataの0番目と2番目の要素だけを抽出してXの配列(150 x 2)に格納    \n",
    "クラス(花びらの種類 0:Iris-Setosa, 1:Iris-Versicolour, 2:Iris-Virginica)を y(150 x 1)に格納"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ガウシアンカーネルで ovr(one-vs-rest) と ovo(one-vs-one) の比較を行う  \n",
    "ディフォルトで decision_function_shape='ovr'であるが，敢えて明示的に指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C=0.5, kernel='rbf', decision_function_shape='ovr').fit(X,y)\n",
    "print(clf)\n",
    "y_pred = clf.predict(X)\n",
    "print('Accuracy = ',accuracy_score(y, y_pred))\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X,y, clf=clf,  legend=2)\n",
    "plt.xlabel('sepal length [cm]')\n",
    "plt.ylabel('petal length [cm]')\n",
    "plt.title('SVM with RBF, ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decision_function_shape='ovo'とする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C=0.5, kernel='rbf', decision_function_shape='ovo').fit(X,y)\n",
    "print(clf)\n",
    "y_pred = clf.predict(X)\n",
    "print('Accuracy = ',accuracy_score(y, y_pred))\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(X,y, clf=clf,  legend=2)\n",
    "plt.xlabel('sepal length [cm]')\n",
    "plt.ylabel('petal length [cm]')\n",
    "plt.title('SVM with RBF, ovo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ovrとovoとで，あまり差がないことが認められた"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に，グリッドサーチを用いて，irisデータに対する最良のクラス分類器を求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グリッドサーチ用パラメータを設定\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly'), 'C':[0.1, 1.0, 10.0], \n",
    "              'gamma':[0.01, 0.1, 1.0, 10.0], 'decision_function_shape':('ovo', 'ovr')}\n",
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グリッドサーチを実行\n",
    "clf = GridSearchCV(svm, parameters, scoring='accuracy', cv=5) #交差検証のデータ分割を5とした\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最良パラメータを表示\n",
    "print('Best accuracy =', clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多項式カーネルで，  \n",
    "decision_function_shape='ovo'の方が'ovr'よりも識別精度が高い結果を得た"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適パラメータによる識別器を全データに適用，テストデータは後述\n",
    "bst_clf = clf.best_estimator_\n",
    "y_est = bst_clf.predict(X)\n",
    "print('Accuracy =', accuracy_score(y, y_est))\n",
    "print(classification_report(y, y_est))\n",
    "plot_decision_regions(X,y, clf=bst_clf,  legend=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のグラフを見て，分類する決定領域が複雑すぎて使いにくいと感じたら，決定領域線を直線で構成する線形カーネルも試してみてください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4つの説明変数を用いる\n",
    "SVCのパラメータの決め方は，本来ならば改めてGridSearchを適用するところであるが，ここでは，上のGrid Searchの結果に従う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target\n",
    "clf = SVC(C=0.1, kernel='poly', gamma=10.0, decision_function_shape='ovo').fit(X,y)\n",
    "print(clf)\n",
    "y_pred = clf.predict(X)\n",
    "print('Accuracy = ',accuracy_score(y, y_pred))\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0],X[:,2], c=y_est, cmap=cm.bwr, edgecolors='k')\n",
    "plt.xlabel('sepal length [cm]')\n",
    "plt.ylabel('petal length [cm]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,1],X[:,3], c=y_est, cmap=cm.bwr, edgecolors='k')\n",
    "plt.xlabel('sepal width [cm]')\n",
    "plt.ylabel('petal widht [cm]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python3-caret2test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
