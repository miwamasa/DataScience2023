{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture8　パターン認識2（クラスタリング）\n",
    "<div dir='rtl'>\n",
    "2022.4岩政\n",
    "</div>\n",
    "\n",
    "## クラスタリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kMeans(K平均法)\n",
    "#### make_blobsを用いたクラスタリング（教師なし）\n",
    "kMeans http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html<br>\n",
    "make_blobs() サンプルデータの生成　sklearn.datasets.make_blobs<br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import cm\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import  accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(  #今回，目的変数（教師データ）yは用いない\n",
    "    n_samples=600,  # サンプル数\n",
    "    n_features=2,    # データ（説明変数）の特徴量の種類\n",
    "    centers=4,       # データのグループ数\n",
    "    cluster_std=1.0, # データのばらつきの標準偏差\n",
    "    random_state=2)  # 確率変数の再現性を設定\n",
    "X_train = X\n",
    "y_train = y\n",
    "plt.scatter(X_train[:,0], X_train[:,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "散布図を見ると3つのグループ（クラスタ）に見えるので，クラスタを3つとして分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)\n",
    "y_train_est = kmeans.fit_predict(X_train)\n",
    "#print(y_train_est[0:20])\n",
    "plt.scatter(X_train[:,0], X_train[:,1], c=y_train_est, cmap=cm.bwr, edgecolors='k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = kmeans.cluster_centers_\n",
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "radii = [cdist(X_train[y_train_est == i], [center]).max()\n",
    "            for i, center in enumerate(centers)]\n",
    "radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the representation of the KMeans model\n",
    "centers = kmeans.cluster_centers_\n",
    "radii = [cdist(X_train[y_train_est == i], [center]).max()\n",
    "            for i, center in enumerate(centers)]\n",
    "fig, ax = plt.subplots(facecolor=\"w\")\n",
    "ax.axis('equal')\n",
    "#plt.scatter(X_train[:,0], X_train[:,1], c=y_train_est, cmap=cm.bwr, edgecolors='k')\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train_est,cmap=cm.bwr, edgecolors='k')\n",
    "for c, r in zip(centers, radii):\n",
    "        #ax.add_patch(plt.Circle(c, r, fc='#CCCCCC', lw=3, alpha=0.4, zorder=1))\n",
    "        ax.add_patch(plt.Circle(c, r,fill=False,color = 'k'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_kmeans(kmeans, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クラスタを4つとして分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4)\n",
    "cluster = kmeans.fit(X_train)\n",
    "y_train_est = kmeans.predict(X_train)\n",
    "#print(y_train_est[0:20])\n",
    "plt.scatter(X_train[:,0], X_train[:,1], c=y_train_est, cmap=cm.bwr, edgecolors='k')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の2つの結果を見て，クラスタ数が３または４なのか，どちらが正しいかは不明としか言いようがない。\n",
    "\n",
    "あまり意味はないが，クラスタ数が真のそれと一致しているとき，クラスタ器の性能評価を行ってみる。\n",
    "ただし，評価は難しい。理由は，y_train_estに与えられるクラスタ番号の順序が一定していないので，\n",
    "y_trainのクラスタ番号に順に合わせる必要がある。\n",
    "そのため，上記まで実行したら，スクリプトはこれ以降のみを扱い，眼で見て修正を行う。\n",
    "あまり意味はないが，クラスタ数が真のそれと一致しているとき，クラスタ器の性能評価を行ってみる。\n",
    "ただし，評価は難しい。理由は，y_train_estに与えられるクラスタ番号の順序が一定していないので，\n",
    "y_trainのクラスタ番号に順に合わせる必要がある。\n",
    "そのため，上記まで実行したら，スクリプトはこれ以降のみを扱い，眼で見て修正を行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "検証するには、accuracy_score関数や、classification_report関数を使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy =%f ' % accuracy_score(y_train, y_train_est))\n",
    "print(classification_report(y_train, y_train_est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K平均法を回帰に使う、ボストン住宅価格データセット\n",
    "https://qiita.com/fujin/items/128ed7188f7e7df74f2c#%E5%88%86%E9%A1%9E%E4%BA%88%E6%B8%AC%E7%B2%BE%E5%BA%A6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ボストン住宅価格データセット\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "# 説明変数\n",
    "X = boston.data\n",
    "# 目的変数\n",
    "Y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ表示（特徴量）\n",
    "print(\"データ数 = %d  特徴量 = %d\" % (X.shape[0], X.shape[1]))\n",
    "pd.DataFrame(X, columns=boston.feature_names).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ表示（目的変数）\n",
    "print(\"データ数 = %d\" % (Y.shape[0]))\n",
    "print(Y[:10]) # 先頭 10件表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明変数に部屋数のみ使用\n",
    "X = boston.data[:, [5]] # 部屋数\n",
    "\n",
    "# トレーニング・テストデータ分割\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0)\n",
    "\n",
    "# プロット\n",
    "plt.xlabel(\"RM\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.plot(X_train, Y_train, \"o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "list_k = []\n",
    "list_score = []\n",
    "for k in range(1, 21):\n",
    "  # KNeighborsClassifier\n",
    "  knr = KNeighborsRegressor(n_neighbors=k)\n",
    "  knr.fit(X_train, Y_train)\n",
    "\n",
    "  # 予測　\n",
    "  Y_pred = knr.predict(X_test)\n",
    "\n",
    "  #\n",
    "  # 評価\n",
    "  #\n",
    "  # 平均絶対誤差(MAE)\n",
    "  mae = mean_absolute_error(Y_test, Y_pred)\n",
    "  # 平方根平均二乗誤差（RMSE）\n",
    "  rmse = np.sqrt(mean_squared_error(Y_test, Y_pred))  \n",
    "  # スコア R^2\n",
    "  score = knr.score(X_test, Y_test)\n",
    "\n",
    "  print(\"[%d] MAE = %.2f,  RMSE = %.2f,  score = %.2f\" % (k, mae, rmse, score))\n",
    "\n",
    "  list_k.append(k)\n",
    "  list_score.append(score)\n",
    "\n",
    "# プロット\n",
    "plt.ylim(0, 0.7)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.title('R^2')\n",
    "plt.plot(list_k, list_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "・平均絶対誤差(MAE)\n",
    "正解値と予測値の差分の絶対値を平均したもの\n",
    "・平方根平均二乗誤差（RMSE）\n",
    "正解値と予測値の差分の二乗を平均し、平方したもの\n",
    "```\n",
    "\n",
    "K = 6 以降、ほとんど変化がありません。\n",
    "K 値は 6 で良いようです"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knr = KNeighborsRegressor(n_neighbors=6)\n",
    "knr.fit(X_train, Y_train)\n",
    "\n",
    "# 予測　\n",
    "list_pred = knr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_pred),len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テストデータの部屋数を使った住宅価格の予測値をプロットしてみます。\n",
    "青が実際の価格、赤が予測価格になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータ上での正解値（青）と予測値（赤）をプロット\n",
    "#K6_Pred = np.array(list_pred)[5]\n",
    "\n",
    "K6_Pred= list_pred\n",
    "plt.xlabel(\"RM\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.plot(X_test, K6_Pred, \"ro\")\n",
    "plt.plot(X_test, Y_test, \"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 凝集型の階層クラスタリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.cluster import hierarchy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[2,1], [1,1], [1,4], [2,5], [4,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(5,5))\n",
    "plt.xlim(0,6)\n",
    "plt.ylim(0,6)\n",
    "plt.grid()\n",
    "plt.scatter(data[:,0], data[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scipy.cluster.hierarchy.linkage<br>\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html#scipy.cluster.hierarchy.linkage\n",
    "scipy.cluster.hierarchy.dendrogram<br>\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.dendrogram.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "群平均法：method='average'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ave = hierarchy.linkage(data, method='average')\n",
    "print(result_ave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = hierarchy.dendrogram(result_ave)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ward法：method='ward'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ward = hierarchy.linkage(data, 'ward')\n",
    "print(result_ward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = hierarchy.dendrogram(result_ward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 富山県の市町村別人口動態\n",
    "人口移動調査　http://www.pref.toyama.jp/sections/1015/lib/jinko/　の中にある。<br>\n",
    "オリジナルデータは次：url = 'http://www.pref.toyama.jp/sections/1015/lib/jinko/_dat_h29/jinko_dat005.xls'<br>\n",
    "これをローカルフォルダに保存して，これを読込んで使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install japanize-matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.cluster import hierarchy\n",
    "import japanize_matplotlib\n",
    "japanize_matplotlib.japanize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd==2.0.1 in c:\\python38\\lib\\site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xlrd==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データがtoyama.jpからダウンロードできない場合は、エラーとなる場合は、ファイルをColabにアップロードして使う\n",
    "\n",
    "url = 'http://www.pref.toyama.jp/sections/1015/lib/jinko/_dat_h29/jinko_dat005.xls'\n",
    "url = 'https://raw.githubusercontent.com/miwamasa/DataScience2022/main/notebooks/data/jinko_dat005.xls'\n",
    "data_orig = pd.read_excel(url, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データのフォーマットを見て，必要，不必要な行，列を判別する\n",
    "data = data_orig.drop([0,1,2,3,4],axis=0)\n",
    "# drop=True: indexの降り直し,  inplace=True: 書き換えは自身のメモリで行う\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記を見て，市の名前（カラム0），自然増加（カラム2），転入総数（カラム6），転出総数（カラム9）を用いることとし，これをDataFrame dfに結合する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([data.iloc[:,0], data.iloc[0:,2], data.iloc[0:,6], data.iloc[0:,9]], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfの各列にラベルを与える, city:市の名前，natural:自然増加, in:転入総数，out:転出総\n",
    "df.columns = ['city', 'natural', 'in', 'out']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相関図（横軸：自然増加，縦軸：転入総数）をプロットする。このとき，各点に市の名前を付加する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = df.city\n",
    "city_labels = list(names) # dendrogramへの入力はリスト形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(8,4)) # (22,18)\n",
    "#plt.rcParams['font.family'] ='Yu Mincho' # 日本語フォントを使うため\n",
    "plt.xlabel('natural')\n",
    "plt.ylabel('in')\n",
    "plt.scatter(df['natural'], df['in'])\n",
    "for i, text in enumerate(df.city):\n",
    "    plt.annotate(text, xy=(df['natural'][i], df['in'][i]), size=10 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df2 は，クラスタ分析のために，cityを削除したデータフレームであ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(8,4))\n",
    "df2 = df.drop('city',axis=1)\n",
    "Z = hierarchy.linkage(df2, 'ward')\n",
    "dn = hierarchy.dendrogram(Z, labels=city_labels, leaf_rotation=90.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 相関図\n",
    "念のため，各変数同士の相関図を見る。<br>\n",
    "seabornのプロットは，バージョン0.9.0から，この例のようなデータセットの種類の数に応じた色数を明示的に用意することが求められる。<br>\n",
    "そうでないと，次のエラーが現れる \"ValueError: color kwarg must have one color per dataset\"<br>\n",
    "ここでは，簡単に，hue='out'と指定した。ここに，'out'はdfのラベル名。幾つかのWarningが現れるが，気にしないことにする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='out')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記の結果を見て，in, outに強い相関が有ることが認められる。naturalと（in, out）にも負の相関が認められるが，若干，外れる市町村があり，この原因究明も興味深い調査となるであろう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主成分分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データを作ります（make_blob)、数は200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "X = np.dot(rng.rand(2, 2), rng.randn(2, 200)).T\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2次元の主成分分析します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得られた主成分を見ます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_vector(v0, v1, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    arrowprops=dict(arrowstyle='->',\n",
    "                    linewidth=2,\n",
    "                    facecolor='red', edgecolor='red',\n",
    "                    shrinkA=0, shrinkB=0)\n",
    "    ax.annotate('', v1, v0, arrowprops=arrowprops)\n",
    "\n",
    "# plot data\n",
    "plt.scatter(X[:, 0], X[:, 1], alpha=0.2)\n",
    "for length, vector in zip(pca.explained_variance_, pca.components_):\n",
    "    v = vector * 3 * np.sqrt(length)\n",
    "    draw_vector(pca.mean_, pca.mean_ + v)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA as dimensionality reduction\n",
    "\n",
    "次元圧縮をする例です。 2次元のデータを１次元に次元圧縮します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "print(\"original shape:   \", X.shape)\n",
    "print(\"transformed shape:\", X_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次元圧縮されたデータを、元の次元に戻して可視化します。\n",
    "\n",
    "一次元（斜め上になってますが）に射影されているような感じになってます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pca.inverse_transform(X_pca)\n",
    "plt.scatter(X[:, 0], X[:, 1], alpha=0.2)\n",
    "plt.scatter(X_new[:, 0], X_new[:, 1], alpha=0.8)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA for visualization: Hand-written digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(2)  # project from 64 to 2 dimensions\n",
    "projected = pca.fit_transform(digits.data)\n",
    "print(digits.data.shape)\n",
    "print(projected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(projected[:, 0], projected[:, 1],\n",
    "            c=digits.target, edgecolor='none', alpha=0.5,\n",
    "            cmap=plt.cm.get_cmap('tab10', 10))\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import sklearn.datasets\n",
    "\n",
    "digits, label = sklearn.datasets.load_digits(return_X_y=True)\n",
    "digits = digits / 255\n",
    "digits2d = TSNE(n_components=2).fit_transform(digits)\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "for i in range(10):\n",
    "    target = digits2d[label == i]\n",
    "    ax.scatter(x=target[:, 0], y=target[:, 1], label=str(i), alpha=0.5)\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ガウス混合分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# irisデータセットのロード\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['label'] = iris.target\n",
    "\n",
    "# 種類 (ラベル) によって、サンプル数を変えます\n",
    "d1 = df[df['label'] == 0].sample(30)  # setosa\n",
    "d2 = df[df['label'] == 1].sample(50)  # versicolor\n",
    "d3 = df[df['label'] == 2].sample(40)  # virginica\n",
    "\n",
    "# 萼片長のデータのみを使う\n",
    "X = pd.concat([d1['sepal length (cm)'], d2['sepal length (cm)'], d3['sepal length (cm)']])\n",
    "Y = pd.concat([d1['label'], d2['label'], d3['label']])\n",
    "\n",
    "# ヒストグラム\n",
    "plt.hist([X[Y==0], X[Y==1], X[Y==2]], bins=np.arange(X.min(), X.max(), 0.2), stacked=True, label=iris.target_names)\n",
    "plt.title('sepal length histgram')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GaussianMixtureの学習\n",
    "gmm = GaussianMixture(\n",
    "    n_components=3,\n",
    "    covariance_type='spherical'\n",
    ").fit(\n",
    "    np.array(X).reshape(-1, 1)  # 次元数2を入力とするため変形\n",
    ")\n",
    "\n",
    "# 重み\n",
    "print(gmm.weights_)\n",
    "# [0.309359   0.43752389 0.25311711]\n",
    "\n",
    "# 期待値\n",
    "print(gmm.means_)\n",
    "# [[5.80722255]\n",
    "#  [6.57885203]\n",
    "#  [4.93215112]]\n",
    "\n",
    "# 分散\n",
    "print(gmm.covariances_)\n",
    "# [0.10564111 0.32196481 0.06607687]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "x = np.linspace(3, 9, 600)\n",
    "\n",
    "gd1 = norm.pdf(x, gmm.means_[0, -1], np.sqrt(gmm.covariances_[0]))\n",
    "gd2 = norm.pdf(x, gmm.means_[1, -1], np.sqrt(gmm.covariances_[1]))\n",
    "gd3 = norm.pdf(x, gmm.means_[2, -1], np.sqrt(gmm.covariances_[2]))\n",
    "    \n",
    "plt.plot(x, gmm.weights_[0] * gd1, label='gd1',color='C1')\n",
    "plt.plot(x, gmm.weights_[1] * gd2, label='gd2',color='C2')\n",
    "plt.plot(x, gmm.weights_[2] * gd3, label='gd3',color='C0')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "X, y_true = make_blobs(n_samples=400, centers=4,\n",
    "                       cluster_std=0.60, random_state=0)\n",
    "X = X[:, ::-1] # flip axes for better plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data with K Means Labels\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(4, random_state=0)\n",
    "labels = kmeans.fit(X).predict(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def plot_kmeans(kmeans, X, n_clusters=4, rseed=0, ax=None):\n",
    "    labels = kmeans.fit_predict(X)\n",
    "\n",
    "    # plot the input data\n",
    "    ax = ax or plt.gca()\n",
    "    ax.axis('equal')\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)\n",
    "\n",
    "    # plot the representation of the KMeans model\n",
    "    centers = kmeans.cluster_centers_\n",
    "    radii = [cdist(X[labels == i], [center]).max()\n",
    "             for i, center in enumerate(centers)]\n",
    "    for c, r in zip(centers, radii):\n",
    "        ax.add_patch(plt.Circle(c, r, fc='#CCCCCC', lw=3, alpha=0.5, zorder=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=0)\n",
    "plot_kmeans(kmeans, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(13)\n",
    "X_stretched = np.dot(X, rng.randn(2, 2))\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=0)\n",
    "plot_kmeans(kmeans, X_stretched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generalizing E–M: Gaussian Mixture Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=4).fit(X)\n",
    "labels = gmm.predict(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = gmm.predict_proba(X)\n",
    "print(probs[:5].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 50 * probs.max(1) ** 2  # square emphasizes differences\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', s=size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "def draw_ellipse(position, covariance, ax=None, **kwargs):\n",
    "    \"\"\"Draw an ellipse with a given position and covariance\"\"\"\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    # Convert covariance to principal axes\n",
    "    if covariance.shape == (2, 2):\n",
    "        U, s, Vt = np.linalg.svd(covariance)\n",
    "        angle = np.degrees(np.arctan2(U[1, 0], U[0, 0]))\n",
    "        width, height = 2 * np.sqrt(s)\n",
    "    else:\n",
    "        angle = 0\n",
    "        width, height = 2 * np.sqrt(covariance)\n",
    "    \n",
    "    # Draw the Ellipse\n",
    "    for nsig in range(1, 4):\n",
    "        ax.add_patch(Ellipse(position, nsig * width, nsig * height,\n",
    "                             angle, **kwargs))\n",
    "        \n",
    "def plot_gmm(gmm, X, label=True, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    labels = gmm.fit(X).predict(X)\n",
    "    if label:\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)\n",
    "    else:\n",
    "        ax.scatter(X[:, 0], X[:, 1], s=40, zorder=2)\n",
    "    ax.axis('equal')\n",
    "    \n",
    "    w_factor = 0.2 / gmm.weights_.max()\n",
    "    for pos, covar, w in zip(gmm.means_, gmm.covariances_, gmm.weights_):\n",
    "        draw_ellipse(pos, covar, alpha=w * w_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=4, random_state=42)\n",
    "plot_gmm(gmm, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=4, covariance_type='full', random_state=42)\n",
    "plot_gmm(gmm, X_stretched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
